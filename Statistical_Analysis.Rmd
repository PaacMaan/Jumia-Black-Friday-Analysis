---
title: "Jumia_black_Friday_analysis"
author: "Ayoub Rmidi"
date: "5 December 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
library(tm)
library(arabicStemR)
library(wordcloud)
library(lubridate)
```

## Data Science - Insights Extraction - Jumia Black Friday Morocco
<br>
<h1>Introduction : </h1>
<h4>This is a notebook covering a statitical analysis and insight extraction of Jumia Black Friday promotions in Morocco, based on user's reviews in the Facebook Official page ofJumia Morocco during November, 2017 .</h4><br>

<h2>1. Data Exploration : </h2>
<b>First of all we load our data set as a data frame so that we can manipulate it easily</b>
```{r Jumia_black_Friday_analysis}
# loading the reviews data set
df <- read.csv(file = "final_data.csv", stringsAsFactors = FALSE)
# get a summary of our data frame
glimpse(df)
```
<b>Now lets have a better visualisation for our data set, so that we can get things much clear</b>
```{r}
# Collect how many rating we have per each class of rating which is from 1 to 5
star_1 <- length(which(df$rating == 1))
star_2 <- length(which(df$rating == 2))
star_3 <- length(which(df$rating == 3))
star_4 <- length(which(df$rating == 4))
star_5 <- length(which(df$rating == 5))
# Create the Rating and their count vector
Ratings <- c("1", "2", "3", "4", "5")
Count <- c(star_1, star_2, star_3, star_4, star_5)
output <- data.frame(Ratings, Count)
ggplot(data = output, aes(x = Ratings, y = Count)) +
  geom_bar(aes(fill = Ratings), stat = "identity") +
  theme(legend.position = "none") +
  xlab("Ratings") + ylab("Total Count") + ggtitle("Histogram of different ratings during the Black Friday Promotion by Jumia")
```

<b>Taking a closer look, the next Histogram will be showing the frequency of occurences of unigrams, but before that, We first had to prepare a corpus of all the documents in the dataframe.</b>
```{r}
corpus <- Corpus(VectorSource(df$review))
# Inspect the corpus
corpus
# Let's inspect some lines from our corpus
inspect(corpus[22:24])
```
## Data Cleaning
<b>Since our corpus is multilingual, the first thing to do is to remove stopwords and then we clean up the corpus by eliminating numbers, punctuation, white space, and by converting to lower case. In addition, we discard common stop words such as “le”, “la”, “dans”, “sur”, "in", "with", etc. We use the tm_map() function from the ‘tm’ package to this end.</b>
```{r echo=FALSE}
 #Use dplyr's  %>% (pipe) utility to do this neatly.
removeStopWords(df$review, defaultStopwordList=TRUE, customStopwordList=NULL)
```

```{r}
corpus.clean <- corpus %>%
  tm_map(content_transformer(tolower)) %>% 
  tm_map(removePunctuation) %>%
  tm_map(removeNumbers) %>%
  tm_map(removeWords, stopwords(kind="fr")) %>%
  tm_map(removeWords, stopwords(kind="en")) %>%
  tm_map(stripWhitespace)

#change date format for size reduction reasons we will keep only dates without time
df$date <- as.Date(df$date)
```
## The Document Term Matrix
<b>We represent the bag of words tokens with a document term matrix (DTM). The rows of the DTM correspond to documents in the collection, columns correspond to terms, and its elements are the term frequencies. We use a built-in function from the ‘tm’ package to create the DTM.</b>
```{r}
dtm <- DocumentTermMatrix(corpus.clean)
# Inspect the dtm
inspect(dtm[50:60, 15:21])
```

<b>And here we get our histogram showing the frequency of occurences of unigrams in the corpus.</b>
```{r}
# Frggplot(df, aes(x = rating, fill = gender)) + geom_bar()equency
freq <- sort(colSums(as.matrix(dtm)), decreasing=TRUE)
wf <- data.frame(word=names(freq), freq=freq)
# Plot Histogram
subset(wf, freq>40)    %>%
        ggplot(aes(word, freq)) +
        geom_bar(stat="identity", fill="lightblue", colour="deepskyblue") +
        theme(axis.text.x=element_text(angle=45, hjust=1)) +
        ggtitle("Histogram of occurences frequency during the Black Friday Promotion by Jumia")
```

<b>So to end up with data exploration, we will generate the Word cloud representaion</b> 
```{r}
m <- as.matrix(TermDocumentMatrix(corpus.clean))
v <- sort(rowSums(m), decreasing=TRUE)
d <- data.frame(word = names(v), freq=v)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
          max.words=100, random.order=FALSE, rot.per=0.35,
          colors=brewer.pal(8, "Dark2"))
```

## Let's go deeper with Statistical insights
<b>In the following plot we will have a more detailled representation showing how reviews were distributed by gender</b>
```{r}
ggplot(df, aes(x = rating, fill = gender)) +
  geom_bar(position = "dodge") +
  ggtitle("Distribution of different ratings during the Black Friday Promotion by gender")
```


<b>One of theimportant plot is to visualize how reviews were distributed during time and their frequencies</b>
```{r}
df_temp <- df
ggplot(df, aes(x = date, y = rating)) +  geom_smooth(span = 0.3)
```

<b>Now, we gonna use this data to figure out the Jumia's users real degree of satisfaction. <br/>
<b> The key variable to measure this degree of satisfaction is the "rating". Let's have a look at the general statistical aspects of this variable <br/>
```{r}
summary(df$rating)
#Computing the proportion for each classe
round(prop.table(table(df$rating))*100,3)
```
<b> As we can see from the first summary, the mean value is 1.497 so it's between the class 1 and 2. On the other hand, the median, the 1st quartile and the 3rd quartile are referring to the first class. That show us that a very important amount of the ratings is from the class 1. This can be seen clearly from the proportions of each class, where the class 1 has been observed 85.183% of the times. <br/>
<B> Now, let's see how those ratings are distributed according to genders using boxplots.<br/>
```{r}
boxplot(rating~gender, data = df, main="Distribution of the ratings by genders")
```
<b> From the first sight, we can say that the distribution of the ratings is the same to both males and females. Reffering to the classes 2,3,4 and 5 as with in the boxplots of both genders means that those values are considered to be outliers, this is due to the very low frequency of appearance of those classes in comparaison to the class 1, in fact, the proportions of the four classes combined don't reach the 15% of all the ratings. However, as we said earlier, the class 1 is the most present one, the marks relative to the 1st quartile, the 3rd quartile and the median are barely seen since there all mingled with the main body of the boxplot to refer to the class 1. This emphasize the class 1 proportion of 85.183% found before. <br/>
<b> Now, let see if the mean value 1.497 of the variable rating we got earlier can be generalised outside this sample. In other terms, if we concidered other users of Jumia whom reviews didn't figure in that sample, will there rating's mean be similar to our sample's mean? To be more specific, we need to see if our mean belongs to the interval generated by this test in order to concidere it general.<br/>
<b> To answer this question, we're going to use a statistical test called "STUDENT mean test". But first, we need to make sure that the variable "rating" is normaly distributed.<br/>
``` {r}
qqnorm(df$rating, col= "green",main="Normal Q-Q Plot: Distribution of the variable rating")
qqline(df$rating, col = "red")
```
<b> As we can see from the plot, the "Henry line" (in red) and the majority of the rating's distribution (in green) are almost aligned.
That means that we can say that the variable "rating" follows a normal distribution. Then, We are able to make our "Student maen test" (with a ). <br/>
```{r}
t.test(df$rating,mu=mean(df$rating),conf.level = 0.95)$conf.int
```
<b> Indeed, the mean 1.497 we got earlier belongs to the interval [1.4338,1.5596] generated by this test. This mean is then said to be "significant".<br/>
<b>Now, let's see if the mean of the rating for males is significantly different than the mean for females.<br/>
```{r}
aggregate(rating~gender, data = df, mean)
```
<b>We're going to use the "Student test" for means comparaison.
We already shown that the variable "rating" is normaly distributed, so we can use the test.
We need first to convert those string "N/A"s to the value NA, and put that in a new variable: na.gender.<br/>
```{r}
na.gender = df$gender
na.gender[na.gender=="N/A"]=NA
t.test(df$rating~na.gender)
```
<b> As we can see from the result, the p-value of the test is 0.411 which is way superior to the freedom degree 0.05, therefore we cannot say that the means for males and females are significantly different from one another. And it make sense since the means estimated from the sample are close to each other but still, we cannot conclude. We cannot be absolutly sure but can say that males and females are on the same level of satisfaction, the level 1, reffering to the unsatisfide or negative reviews. <br/>
<b> Now, we're going to try to analyse the relationship between the ratings and the facebook reactions.<br/>
<b>In the following, we're going to focus on the like, love and mad reactions since the other reaction, laugh, sad and Woah, don't provide clear emotion about the review. For instance, we cannot know whether laugh reaction is used because the review is funny or used to mock the review. Of course this ambiguity can be present in the used the reaction but not as intance as in those excluded. <br/>
<b> To make this analysis, we gonna need to make a modification to the data. We need to binarize the variable "rating" to garantee a clear polarity.
For this sake, we're going to be nice to "Jumia" and leave the rating from class 1 as they are  and tuen the rest into 5. Class 1 will than represent the unsatisfied class a and 5 the satisfide one.<br/>
```{r}
bin.rating= ifelse(df$rating==1,1,5)
```
<b> Now, let's see how "like" is used in average.<br/>
```{r}
aggregate(df$Like~bin.rating, data = df, mean)
```
<b> From the first look, we can say that the reviews belonging to the class 1 are more liked than the rest, but let's test that statisticly and see if they are significantly different.
We start, as we saw earlier, by testing the normality of the variable "Like" before using the previously used "STUDENT test" for means comparaison.<br/>
```{r}
qqnorm(df$Like, col= "orange",main="Normal Q-Q Plot: Distribution of the variable Like")
qqline(df$Like, col = "blue")
```
<b> The the "Henry line" (in blue) and the majority of the Like's distribution (in orange) are almost aligned.
The Like variable is then normaly distributed.
Let's compare the means from each class (1 and 5). <br/>
```{r}
t.test(df$Like~bin.rating)
```
<b> The resulted p-value is: 5.347e-11 (almost equal to 0) which is inferior to 0.05 the freedom degree. We can then accept the alternative hypothesis which means that we can say that the means are significantly different from each other.<br/>
<b>We're going to do the same for the variable Love. <br/>
```{r}
aggregate(df$Love~bin.rating, data = df, mean)
```
<b> Those results give the impression that the means are too different. Let's see.<br/>
```{r}
qqnorm(df$Love, col= "yellow",main="Normal Q-Q Plot: Distribution of the variable Love")
qqline(df$Love, col = "green")
```
<b> The variable Love follows the normal distribution, we can do the test. <br/>
```{r}
t.test(df$Love~bin.rating)
```
<b> The p-value is 0.3066 and is superior to the freedom degree 0.05. We cannot reject the null hypothesis. And then, we cannot say that the means are significantly different from in the two classes.<br/>
<b>We can then note that the unsatisfied reviews have been loved in average the same amount of time as the satisfied reviews even if they are way more than the satisfied reviews.<br/>
<b> Now, it's time for Angry variable. <br/>
```{r}
aggregate(df$Angry~bin.rating, data = df, mean)
```
<b> One more time we get the impression that the means are different. We need to see what the statistical test is saying.<br/>
```{r}
qqnorm(df$Angry, col= "pink",main="Normal Q-Q Plot: Distribution of the variable Angry")
qqline(df$Angry, col = "brown")
```
<b> The variable Angry follows the normal distribution, we can do the test.<br/>
```{r}
t.test(df$Angry~bin.rating)
```
<b> The p-value 0.2385 is superior to the freedom degree 0.05. We cannot reject the null hypothesis. Therefore we cannot claim that the means are significantly different. <br/>
<b> Now, we're going to see if there is any relation between the rating and those reactions. And if it's the case, how do they influence each other.<br/>
<b>For that sake, we're going to compute the correlation between those variables using the statistical test of "Pearson".<br/>
<b>Let's start with the likes.<br/>
<b>We demonstrated earlier that both the variable rating and like are following a normal distribution. We are then free to use the Pearson test.<br/>
```{r}
cor.test(df$rating,df$Like, method = "pearson")
```
<b> This test resulted to a p-value of 0.0001697 (close to 0), this is inferior to the freedom degree 0.05. This mean that we can reject the null hypothesis that claims that the correlation is equal to zero.<br/>
```{r}
p <- ggplot(df, aes(Like, rating))
p + geom_point(aes(size = Like,colour = factor(rating)))
```
<b>In other terms, we can say that the variables rating and Like are significantly correlated with a correlation value of -0.09866759 but still, this can be considered as a small strength of association between the two variables. We can speculate from this negative correlation value that variable are evolving in opposite directions. In other words, when the rating is growing, the likes get fewer and vice versa, as shown in the plot above.<br/>
<b>To illustrate how do the the ratings and Likes influente each other, and to make sure that speculations made earlier are correct, we need to build a regression model between the two variables. <br/>
```{r}
reg.like = lm(df$rating~df$Like);reg.like
```
<b> As we can see, the slope provided by the regression model is equal to -0.05157. Which means that the line corresponding to this slope is decreasing as pridicted before. Here's how much the regression line can explain the data. <br/>
```{r}
p <- ggplot(df, aes(df$Like, df$rating))
p <- p + geom_point(aes(size = df$Like,colour = factor(df$rating)))
p + geom_abline(intercept = reg.like$coef[1], slope = reg.like$coef[2])
```
<b> This plot shows us that the class 1 rating (most unsatisfied ones) are the one getting most of the Likes.<br/>
<b> We're going to do the same for the variable Angry. Let's calculate the Pearson's test. <br/>
```{r}
cor.test(df$rating,df$Angry, method = "pearson")
```
<b> We can see that the p-value is equal to the freedom degree 0.05. That means that there is a significant correlation between the ratings and the Love reactions. But still, an estimated correlation of 0.07103963 is not strong enough. This time, the estimated correlation is positive, that insinuate that the variables evolve in the same direction. Let see if it's really the case by building a regression model. <br/>
```{r}
reg.Angry = lm(df$rating~df$Angry);reg.Angry
```
<b> As expected, the slope provided by the regression model is equal to 0.6386, which correspond to a increasing regression line. The following plot illustrate this clearly. <br/>
```{r}
p <- ggplot(df, aes(df$Angry, df$rating))
p <- p + geom_point(aes(size = df$Angry,colour = factor(df$rating)))
p + geom_abline(intercept = reg.Angry$coef[1], slope = reg.Angry$coef[2])
```
<b> It's clear from plot above that the class 5 and 4 rating (corresponding to the most satisfied reviews) are the one getting the most Angry reactions. And the amount of Angry reactions recieved by the class 1 is considerably inferior to the Angry reaction from the class 5. <br/>
<b> Let's see now the developpement of the rations before and after the event called "the black friday" taht took place on November 24 in 2017. <br/>
<b>For this purpose, we're going to split the date into two categories, one before the black friday and one after the black friday. <br/>
```{r}
bin.date= ifelse(df$date < "2017-11-24","Before BF","After BF")
aggregate(rating~bin.date, data = df, mean)
```
<b> By the mean of a boxplot, we're going to rxplore the distribution of the ratings before and after the black friday.<br/>
```{r}
boxplot(rating~bin.date, data = df, main="Distribution of the ratings before and after the Black Friday")
```
<b> <br/>
<b> As we can see, there is a striking difference between the two plots. Before the black friday, even if the 1st quartile, the mean and 3rd quartile are reffering to the class 1 but still, the main body of the boxplot covers all the classes from 1 to 5, that means that they were reviews posts from all the classes. On the opposite side, after the black friday, the body and all the box marks are mingled in the class 1, and the rest of the classes are considered being some ouliers values. That means that after the black friday poeple started getting more unsatisfied from the services of Jumia, even they weren't that satisfied before.<br/>